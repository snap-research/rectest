model:
  _target_: recommender.LlamaRec.model.lru_refactored.LRURec
  bert_hidden_units: 64
  item_num: null # updated in code
  bert_num_blocks: 1 # Max Sequence Length
  bert_dropout: 0.1
  bert_attn_dropout: 0.1

optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 1e-6
  eps: 1e-8

scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 10
  gamma: 0.9

collator_train:
  _target_: baselines.collators.IDOnlyCollateFn
  option: 'random'
  num_candidates: 5

collator_val:
  _target_: baselines.collators.IDOnlyCollateFn
  option: 'random'
  num_candidates: 10000

dataset:
  _target_: baselines.dataloading.SequentialIterableDataset
  data_path: ./data_experiments/movielens/ml100
  min_seq_len: 1
  max_seq_len: 10000

# training
epochs: 10000
batch_size_train: 32
batch_size_val: 64
early_stopping: 50
seed: 43
gradient_accumulation_steps: 2
# evaluation
eval_at_start: true
eval_steps: 80
# metrics
metric_ks: 10
save_metric: 'NDCG'
# infrastructure
device: 'cuda'
number_of_devices: 1
fp16: true
# results/checkpoints
accelerate_checkpoint: null
output_dir: 'sasrec'
